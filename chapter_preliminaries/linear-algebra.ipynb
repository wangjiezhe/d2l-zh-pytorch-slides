{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2098da78",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# 线性代数\n",
    "\n",
    "标量由只有一个元素的张量表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44889577",
   "metadata": {
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(5.), tensor(6.), tensor(1.5000), tensor(9.))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor(3.0)\n",
    "y = torch.tensor(2.0)\n",
    "\n",
    "x + y, x * y, x / y, x**y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d82f481",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "向量可以被视为标量值组成的列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5163ab8",
   "metadata": {
    "origin_pos": 7,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(4)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297e056d",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "通过张量的索引来访问任一元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34dd7630",
   "metadata": {
    "origin_pos": 12,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e1565a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "访问张量的长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d469059b",
   "metadata": {
    "origin_pos": 17,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013d74f2",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "只有一个轴的张量，形状只有一个元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf9bf15e",
   "metadata": {
    "origin_pos": 22,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341ae596",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "通过指定两个分量$m$和$n$来创建一个形状为$m \\times n$的矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1eac085",
   "metadata": {
    "origin_pos": 27,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11],\n",
       "        [12, 13, 14, 15],\n",
       "        [16, 17, 18, 19]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(20).reshape(5, 4)\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66a0813",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "矩阵的转置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "289523ed",
   "metadata": {
    "origin_pos": 32,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  4,  8, 12, 16],\n",
       "        [ 1,  5,  9, 13, 17],\n",
       "        [ 2,  6, 10, 14, 18],\n",
       "        [ 3,  7, 11, 15, 19]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b49d3e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "*对称矩阵*（symmetric matrix）$\\mathbf{A}$等于其转置：$\\mathbf{A} = \\mathbf{A}^\\top$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0eb414b",
   "metadata": {
    "origin_pos": 37,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [2, 0, 4],\n",
       "        [3, 4, 5]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = torch.tensor([[1, 2, 3], [2, 0, 4], [3, 4, 5]])\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44cc700c",
   "metadata": {
    "origin_pos": 42,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B == B.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0e0f73",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "就像向量是标量的推广，矩阵是向量的推广一样，我们可以构建具有更多轴的数据结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f7227a9",
   "metadata": {
    "origin_pos": 47,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]],\n",
       "\n",
       "        [[12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [20, 21, 22, 23]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(24).reshape(2, 3, 4)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f4616c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "给定具有相同形状的任意两个张量，任何按元素二元运算的结果都将是相同形状的张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6c89bd2",
   "metadata": {
    "origin_pos": 52,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.]]),\n",
       " tensor([[ 0.,  2.,  4.,  6.],\n",
       "         [ 8., 10., 12., 14.],\n",
       "         [16., 18., 20., 22.],\n",
       "         [24., 26., 28., 30.],\n",
       "         [32., 34., 36., 38.]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(20, dtype=torch.float32).reshape(5, 4)\n",
    "B = A.clone()\n",
    "A, A + B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdea0f0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "两个矩阵的按元素乘法称为*Hadamard积*（Hadamard product）（数学符号$\\odot$）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1efe4855",
   "metadata": {
    "origin_pos": 57,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.,   1.,   4.,   9.],\n",
       "        [ 16.,  25.,  36.,  49.],\n",
       "        [ 64.,  81., 100., 121.],\n",
       "        [144., 169., 196., 225.],\n",
       "        [256., 289., 324., 361.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A * B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "587335a3",
   "metadata": {
    "origin_pos": 62,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 2,  3,  4,  5],\n",
       "          [ 6,  7,  8,  9],\n",
       "          [10, 11, 12, 13]],\n",
       " \n",
       "         [[14, 15, 16, 17],\n",
       "          [18, 19, 20, 21],\n",
       "          [22, 23, 24, 25]]]),\n",
       " torch.Size([2, 3, 4]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 2\n",
    "X = torch.arange(24).reshape(2, 3, 4)\n",
    "a + X, (a * X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89993c5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "计算其元素的和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32507943",
   "metadata": {
    "origin_pos": 67,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3.]), tensor(6.))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(4, dtype=torch.float32)\n",
    "x, x.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c90279",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "表示任意形状张量的元素和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e0cd60f",
   "metadata": {
    "origin_pos": 72,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 4]), tensor(190.))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape, A.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cc5703",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "指定张量沿哪一个轴来通过求和降低维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "989de0ce-b124-4e92-aab6-a65d7c78133b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.],\n",
       "        [12., 13., 14., 15.],\n",
       "        [16., 17., 18., 19.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9420cc92",
   "metadata": {
    "origin_pos": 77,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([40., 45., 50., 55.]), torch.Size([4]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_sum_axis0 = A.sum(axis=0)\n",
    "A_sum_axis0, A_sum_axis0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50e59a41",
   "metadata": {
    "origin_pos": 82,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 6., 22., 38., 54., 70.]), torch.Size([5]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_sum_axis1 = A.sum(axis=1)\n",
    "A_sum_axis1, A_sum_axis1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1ba976a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:01:43.970587Z",
     "iopub.status.busy": "2023-08-18T07:01:43.969706Z",
     "iopub.status.idle": "2023-08-18T07:01:43.977405Z",
     "shell.execute_reply": "2023-08-18T07:01:43.976340Z"
    },
    "origin_pos": 87,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(190.)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.sum(axis=[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a33400",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "一个与求和相关的量是*平均值*（mean或average）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d901892",
   "metadata": {
    "origin_pos": 92,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(9.5000), tensor(9.5000))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.mean(), A.sum() / A.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65c39834",
   "metadata": {
    "origin_pos": 97,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 8.,  9., 10., 11.]), tensor([ 8.,  9., 10., 11.]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.mean(axis=0), A.sum(axis=0) / A.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100420c3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "计算总和或均值时保持轴数不变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2cc17274",
   "metadata": {
    "origin_pos": 102,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.],\n",
       "        [22.],\n",
       "        [38.],\n",
       "        [54.],\n",
       "        [70.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_A = A.sum(axis=1, keepdims=True)\n",
    "sum_A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3055e67",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "通过广播将`A`除以`sum_A`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63a5b49d",
   "metadata": {
    "origin_pos": 107,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.1667, 0.3333, 0.5000],\n",
       "        [0.1818, 0.2273, 0.2727, 0.3182],\n",
       "        [0.2105, 0.2368, 0.2632, 0.2895],\n",
       "        [0.2222, 0.2407, 0.2593, 0.2778],\n",
       "        [0.2286, 0.2429, 0.2571, 0.2714]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A / sum_A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5074bd29",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "某个轴计算`A`元素的累积总和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27eb9655",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:01:44.033849Z",
     "iopub.status.busy": "2023-08-18T07:01:44.033115Z",
     "iopub.status.idle": "2023-08-18T07:01:44.041281Z",
     "shell.execute_reply": "2023-08-18T07:01:44.040150Z"
    },
    "origin_pos": 112,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  6.,  8., 10.],\n",
       "        [12., 15., 18., 21.],\n",
       "        [24., 28., 32., 36.],\n",
       "        [40., 45., 50., 55.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.cumsum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "794ba101-5cd0-4ebc-a5f0-2439c458b084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([40., 45., 50., 55.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "70665d0c-3edc-4d42-967a-ce255a174264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.],\n",
       "        [22.],\n",
       "        [38.],\n",
       "        [54.],\n",
       "        [70.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.sum(1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e4af0298-3431-45fe-9f09-ef3696a4a3ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  3.,  6.],\n",
       "        [ 4.,  9., 15., 22.],\n",
       "        [ 8., 17., 27., 38.],\n",
       "        [12., 25., 39., 54.],\n",
       "        [16., 33., 51., 70.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.cumsum(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dfe953",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "点积是相同位置的按元素乘积的和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7840d740",
   "metadata": {
    "origin_pos": 117,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3.]), tensor([1., 1., 1., 1.]), tensor(6.))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.ones(4, dtype = torch.float32)\n",
    "x, y, torch.dot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8a3bdc",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "我们可以通过执行按元素乘法，然后进行求和来表示两个向量的点积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dadc2a45",
   "metadata": {
    "origin_pos": 122,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(x * y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4bb53f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "矩阵向量积$\\mathbf{A}\\mathbf{x}$是一个长度为$m$的列向量，\n",
    "其第$i$个元素是点积$\\mathbf{a}^\\top_i \\mathbf{x}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "62c6809c",
   "metadata": {
    "origin_pos": 130,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 4]), torch.Size([4]), tensor([ 14.,  38.,  62.,  86., 110.]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape, x.shape, torch.mv(A, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a86f222",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "我们可以将矩阵-矩阵乘法$\\mathbf{AB}$看作简单地执行$m$次矩阵-向量积，并将结果拼接在一起，形成一个$n \\times m$矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1e3efc16",
   "metadata": {
    "origin_pos": 135,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.,  6.,  6.],\n",
       "        [22., 22., 22.],\n",
       "        [38., 38., 38.],\n",
       "        [54., 54., 54.],\n",
       "        [70., 70., 70.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = torch.ones(4, 3)\n",
    "torch.mm(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061e98c6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$L_2$*范数*是向量元素平方和的平方根：\n",
    "$$\\|\\mathbf{x}\\|_2 = \\sqrt{\\sum_{i=1}^n x_i^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f829c100",
   "metadata": {
    "origin_pos": 140,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = torch.tensor([3.0, -4.0])\n",
    "torch.norm(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b36a33",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$L_1$范数，它表示为向量元素的绝对值之和：\n",
    "$$\\|\\mathbf{x}\\|_1 = \\sum_{i=1}^n \\left|x_i \\right|$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "01356584",
   "metadata": {
    "origin_pos": 145,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(u).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a43fb6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "矩阵\n",
    "的*Frobenius范数*（Frobenius norm）是矩阵元素平方和的平方根：\n",
    "$$\\|\\mathbf{X}\\|_F = \\sqrt{\\sum_{i=1}^m \\sum_{j=1}^n x_{ij}^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a8792ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:01:44.156452Z",
     "iopub.status.busy": "2023-08-18T07:01:44.155694Z",
     "iopub.status.idle": "2023-08-18T07:01:44.163608Z",
     "shell.execute_reply": "2023-08-18T07:01:44.162540Z"
    },
    "origin_pos": 150,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(torch.ones((4, 9)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b92dd3b5-5030-46f4-8ae2-f1ce44405d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7b85177c-ba53-426c-9184-12e1fb1db76c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.],\n",
       "        [12., 13., 14., 15.],\n",
       "        [16., 17., 18., 19.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1f0357b4-bb77-4e92-91d8-7a75478a8573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6., 22., 38., 54., 70.])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "92fe3ebf-1e7f-4d07-b78a-5242fc475f30",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4) must match the size of tensor b (5) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mA\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (5) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "A / A.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7b27e842-87e1-4f92-836e-4f8e9aa20e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.1667, 0.3333, 0.5000],\n",
       "        [0.1818, 0.2273, 0.2727, 0.3182],\n",
       "        [0.2105, 0.2368, 0.2632, 0.2895],\n",
       "        [0.2222, 0.2407, 0.2593, 0.2778],\n",
       "        [0.2286, 0.2429, 0.2571, 0.2714]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A / A.sum(1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dd00f43b-f4c1-42f8-bf45-ba2e1cc97fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `linalg.norm` not found.\n"
     ]
    }
   ],
   "source": [
    "linalg.norm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6122a05a-b161-499c-bdfa-23e7ac4caed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "linalg.norm(A, ord=None, dim=None, keepdim=False, *, out=None, dtype=None) -> Tensor\n",
       "\n",
       "Computes a vector or matrix norm.\n",
       "\n",
       "Supports input of float, double, cfloat and cdouble dtypes.\n",
       "\n",
       "Whether this function computes a vector or matrix norm is determined as follows:\n",
       "\n",
       "- If :attr:`dim` is an `int`, the vector norm will be computed.\n",
       "- If :attr:`dim` is a `2`-`tuple`, the matrix norm will be computed.\n",
       "- If :attr:`dim`\\ `= None` and :attr:`ord`\\ `= None`,\n",
       "  :attr:`A` will be flattened to 1D and the `2`-norm of the resulting vector will be computed.\n",
       "- If :attr:`dim`\\ `= None` and :attr:`ord` `!= None`, :attr:`A` must be 1D or 2D.\n",
       "\n",
       ":attr:`ord` defines the norm that is computed. The following norms are supported:\n",
       "\n",
       "======================     =========================  ========================================================\n",
       ":attr:`ord`                norm for matrices          norm for vectors\n",
       "======================     =========================  ========================================================\n",
       "`None` (default)           Frobenius norm             `2`-norm (see below)\n",
       "`'fro'`                    Frobenius norm             -- not supported --\n",
       "`'nuc'`                    nuclear norm               -- not supported --\n",
       "`inf`                      `max(sum(abs(x), dim=1))`  `max(abs(x))`\n",
       "`-inf`                     `min(sum(abs(x), dim=1))`  `min(abs(x))`\n",
       "`0`                        -- not supported --        `sum(x != 0)`\n",
       "`1`                        `max(sum(abs(x), dim=0))`  as below\n",
       "`-1`                       `min(sum(abs(x), dim=0))`  as below\n",
       "`2`                        largest singular value     as below\n",
       "`-2`                       smallest singular value    as below\n",
       "other `int` or `float`     -- not supported --        `sum(abs(x)^{ord})^{(1 / ord)}`\n",
       "======================     =========================  ========================================================\n",
       "\n",
       "where `inf` refers to `float('inf')`, NumPy's `inf` object, or any equivalent object.\n",
       "\n",
       ".. seealso::\n",
       "\n",
       "        :func:`torch.linalg.vector_norm` computes a vector norm.\n",
       "\n",
       "        :func:`torch.linalg.matrix_norm` computes a matrix norm.\n",
       "\n",
       "        The above functions are often clearer and more flexible than using :func:`torch.linalg.norm`.\n",
       "        For example, `torch.linalg.norm(A, ord=1, dim=(0, 1))` always\n",
       "        computes a matrix norm, but with `torch.linalg.vector_norm(A, ord=1, dim=(0, 1))` it is possible\n",
       "        to compute a vector norm over the two dimensions.\n",
       "\n",
       "Args:\n",
       "    A (Tensor): tensor of shape `(*, n)` or `(*, m, n)` where `*` is zero or more batch dimensions\n",
       "    ord (int, float, inf, -inf, 'fro', 'nuc', optional): order of norm. Default: `None`\n",
       "    dim (int, Tuple[int], optional): dimensions over which to compute\n",
       "        the vector or matrix norm. See above for the behavior when :attr:`dim`\\ `= None`.\n",
       "        Default: `None`\n",
       "    keepdim (bool, optional): If set to `True`, the reduced dimensions are retained\n",
       "        in the result as dimensions with size one. Default: `False`\n",
       "\n",
       "Keyword args:\n",
       "    out (Tensor, optional): output tensor. Ignored if `None`. Default: `None`.\n",
       "    dtype (:class:`torch.dtype`, optional): If specified, the input tensor is cast to\n",
       "        :attr:`dtype` before performing the operation, and the returned tensor's type\n",
       "        will be :attr:`dtype`. Default: `None`\n",
       "\n",
       "Returns:\n",
       "    A real-valued tensor, even when :attr:`A` is complex.\n",
       "\n",
       "Examples::\n",
       "\n",
       "    >>> from torch import linalg as LA\n",
       "    >>> a = torch.arange(9, dtype=torch.float) - 4\n",
       "    >>> a\n",
       "    tensor([-4., -3., -2., -1.,  0.,  1.,  2.,  3.,  4.])\n",
       "    >>> B = a.reshape((3, 3))\n",
       "    >>> B\n",
       "    tensor([[-4., -3., -2.],\n",
       "            [-1.,  0.,  1.],\n",
       "            [ 2.,  3.,  4.]])\n",
       "\n",
       "    >>> LA.norm(a)\n",
       "    tensor(7.7460)\n",
       "    >>> LA.norm(B)\n",
       "    tensor(7.7460)\n",
       "    >>> LA.norm(B, 'fro')\n",
       "    tensor(7.7460)\n",
       "    >>> LA.norm(a, float('inf'))\n",
       "    tensor(4.)\n",
       "    >>> LA.norm(B, float('inf'))\n",
       "    tensor(9.)\n",
       "    >>> LA.norm(a, -float('inf'))\n",
       "    tensor(0.)\n",
       "    >>> LA.norm(B, -float('inf'))\n",
       "    tensor(2.)\n",
       "\n",
       "    >>> LA.norm(a, 1)\n",
       "    tensor(20.)\n",
       "    >>> LA.norm(B, 1)\n",
       "    tensor(7.)\n",
       "    >>> LA.norm(a, -1)\n",
       "    tensor(0.)\n",
       "    >>> LA.norm(B, -1)\n",
       "    tensor(6.)\n",
       "    >>> LA.norm(a, 2)\n",
       "    tensor(7.7460)\n",
       "    >>> LA.norm(B, 2)\n",
       "    tensor(7.3485)\n",
       "\n",
       "    >>> LA.norm(a, -2)\n",
       "    tensor(0.)\n",
       "    >>> LA.norm(B.double(), -2)\n",
       "    tensor(1.8570e-16, dtype=torch.float64)\n",
       "    >>> LA.norm(a, 3)\n",
       "    tensor(5.8480)\n",
       "    >>> LA.norm(a, -3)\n",
       "    tensor(0.)\n",
       "\n",
       "Using the :attr:`dim` argument to compute vector norms::\n",
       "\n",
       "    >>> c = torch.tensor([[1., 2., 3.],\n",
       "    ...                   [-1, 1, 4]])\n",
       "    >>> LA.norm(c, dim=0)\n",
       "    tensor([1.4142, 2.2361, 5.0000])\n",
       "    >>> LA.norm(c, dim=1)\n",
       "    tensor([3.7417, 4.2426])\n",
       "    >>> LA.norm(c, ord=1, dim=1)\n",
       "    tensor([6., 6.])\n",
       "\n",
       "Using the :attr:`dim` argument to compute matrix norms::\n",
       "\n",
       "    >>> A = torch.arange(8, dtype=torch.float).reshape(2, 2, 2)\n",
       "    >>> LA.norm(A, dim=(1,2))\n",
       "    tensor([ 3.7417, 11.2250])\n",
       "    >>> LA.norm(A[0, :, :]), LA.norm(A[1, :, :])\n",
       "    (tensor(3.7417), tensor(11.2250))\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.linalg.norm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "84fae256-d8bc-4544-a35c-24f37e75070d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(49.6991)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import linalg as LA\n",
    "LA.norm(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0ca6929b-1d5a-448a-a7a7-e585e5222832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(49.6991)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eca50ea6-e6fb-4350-9db5-beeeb99ac50a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.,  6.,  6.],\n",
       "        [22., 22., 22.],\n",
       "        [38., 38., 38.],\n",
       "        [54., 54., 54.],\n",
       "        [70., 70., 70.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A @ B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "91c97de8-2b67-4916-a4a2-c2631f66d617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 14.,  38.,  62.,  86., 110.])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A@x"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "required_libs": [],
  "rise": {
   "autolaunch": true,
   "enable_chalkboard": true,
   "overlay": "<div class='my-top-right'><img height=80px src='http://d2l.ai/_static/logo-with-text.png'/></div><div class='my-top-left'></div>",
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
